{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigment 6\n",
    "Karl-Axel JÃ¶nsson BME4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' #To get rid of annoying tf messages\n",
    "from matplotlib import pyplot as plt\n",
    "import cinc2022metrics as cm # Our own little metrics file\n",
    "from tensorflow import keras\n",
    "from keras import utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.read_csv('/Users/karl-axeljonsson/Downloads/feats.csv', header=None, usecols = [i+1 for i in range(22)]) \n",
    "murmur_labels = pd.read_csv('/Users/karl-axeljonsson/Downloads/murmur_labels.csv', header=None)\n",
    "outcome_labels = pd.read_csv('/Users/karl-axeljonsson/Downloads/outcome_labels.csv', header=None)\n",
    "\n",
    "feats = feats.to_numpy()\n",
    "murmur_labels = murmur_labels.to_numpy().ravel()\n",
    "outcome_labels = outcome_labels.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train_murmur,y_test_murmur,y_train_outcome,y_test_outcome=train_test_split(feats, murmur_labels, outcome_labels, test_size=0.2,random_state=2)\n",
    "murmur_classes=['Present', 'Unknown', 'Absent']\n",
    "outcome_classes=['Abnormal', 'Normal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.557,0.376,0.299,0.735,0.673,14280.360\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.521,0.520,0.517,0.519,0.503,14648.111\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.590,0.552,0.530\n",
      "AUPRC,0.282,0.785,0.060\n",
      "F-measure,0.050,0.847,0.000\n",
      "Accuracy,0.026,0.979,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.521,0.521\n",
      "AUPRC,0.460,0.580\n",
      "F-measure,0.492,0.543\n",
      "Accuracy,0.494,0.540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(n_estimators=30,learning_rate=0.1).fit(X_train,y_train_murmur)\n",
    "y_hat_murmur=clf.predict_proba(X_test)\n",
    "clf_2=GradientBoostingClassifier(n_estimators=50, learning_rate=0.2, max_leaf_nodes=10).fit(X_train, y_train_outcome)\n",
    "y_hat_outcome=clf_2.predict_proba(X_test)\n",
    "\n",
    "y_test_murmur_bin=utils.to_categorical(y_test_murmur)\n",
    "y_test_outcome_bin=utils.to_categorical(y_test_outcome)\n",
    "\n",
    "\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_hat_murmur,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_hat_outcome, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.465,0.315,0.301,0.672,0.621,14718.995\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.535,0.529,0.513,0.513,0.523,14167.836\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.415,0.416,0.566\n",
      "AUPRC,0.175,0.707,0.062\n",
      "F-measure,0.103,0.800,0.000\n",
      "Accuracy,0.079,0.879,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.535,0.535\n",
      "AUPRC,0.512,0.547\n",
      "F-measure,0.505,0.521\n",
      "Accuracy,0.528,0.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=BaggingClassifier(KNeighborsClassifier(3),max_features=1, max_samples=5).fit(X_train, y_train_murmur)\n",
    "y_hat_murmur=clf.predict_proba(X_test)\n",
    "clf_2=BaggingClassifier(KNeighborsClassifier(2),max_features=2).fit(X_train,y_train_outcome)\n",
    "y_hat_outcome=clf_2.predict_proba(X_test)\n",
    "\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_hat_murmur,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_hat_outcome, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.549,0.358,0.285,0.746,0.679,14718.995\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.536,0.538,0.496,0.513,0.662,11959.202\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.506,0.574,0.568\n",
      "AUPRC,0.211,0.791,0.071\n",
      "F-measure,0.000,0.855,0.000\n",
      "Accuracy,0.000,1.000,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.536,0.536\n",
      "AUPRC,0.497,0.579\n",
      "F-measure,0.589,0.403\n",
      "Accuracy,0.742,0.310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=10).fit(X_train,y_train_murmur)\n",
    "y_hat_murmur=clf.predict_proba(X_test)\n",
    "clf_2=AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=4).fit(X_train,y_train_outcome)\n",
    "y_hat_outcome=clf_2.predict_proba(X_test)\n",
    "\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_hat_murmur,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_hat_outcome, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.417,0.348,0.283,0.735,0.669,14718.995\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.488,0.503,0.504,0.508,0.470,15392.204\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.479,0.449,0.322\n",
      "AUPRC,0.195,0.708,0.139\n",
      "F-measure,0.000,0.848,0.000\n",
      "Accuracy,0.000,0.986,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.488,0.488\n",
      "AUPRC,0.467,0.538\n",
      "F-measure,0.462,0.546\n",
      "Accuracy,0.449,0.560\n",
      "\n",
      "hej\n"
     ]
    }
   ],
   "source": [
    "clf1=RandomForestClassifier(n_estimators=50,random_state=1).fit(X_train,y_train_murmur)\n",
    "clf2=LogisticRegression(random_state=1).fit(X_train,y_train_murmur)\n",
    "clf3=KNeighborsClassifier().fit(X_train,y_train_murmur)\n",
    "\n",
    "clf=VotingClassifier(estimators=[('rf', clf1), ('lr', clf2), ('knn', clf3)],voting='soft').fit(X_train,y_train_murmur)\n",
    "y_hat_murmur=clf.predict_proba(X_test)\n",
    "\n",
    "clf_2=VotingClassifier(estimators=[('rf', clf1), ('lr', clf2), ('knn', clf3)],voting='soft').fit(X_train,y_train_outcome)\n",
    "y_hat_outcome=clf_2.predict_proba(X_test)\n",
    "\n",
    "\n",
    "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_hat_murmur,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]                             \n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_hat_outcome, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "\n",
    "cm.print_scores(murmur_scores, outcome_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The best weighted accuracy received was from AdaBoost or bagging, approx 0.1 from the best result in the competition. The cost was drastically lowest in AdaBoost than any other of the other ones with only 800 from the lowest value in the competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
